General notes:

The relationship between w_a and w_p is:

w_p = w_a * (1 - a)/(a_p - a)




---

** astro-ph/06059591 **

The Dark Energy Task Force (DETF) basically laid out the case for pursuing
dark energy. They proposed several things.

First, they proposed (or probably adopted?) a parametrization of a
time-varying w as

w = w_0 + (1-a)w_a

Which has the virtue that w=w_0 today - is simply a first order Taylor
expansion.

Of course we don't directly measure Lambda. What has actually been measured is
more subtle. We actually measure is a''(t) > 0. According to the Friedmann
acceleration equation,

a''(t) = -4piG/3 * (rho + 3*p) + lambda/3    (p. 27)

Now, the DETF point out that a''(t) > 0 could be explained by:

1.) dark energy - i.e. some component where w < -1/3
2.) cosmological constant
3.) modification to GR, standard cosmological model, etc.

However, I think a better (and probably more widespread) usage is that 1.) and
2.) are both dark energy, and 2.) is just a special case of 1.) (w=-1). This
does bring up a potentially important point which is that the observational
problem is not that we observe dark energy, but that we observe an
acceleration _for which an additional fluid component is one possible
explanation_.

---

** 1209.0922 **

Gives an overview of the theoretical and observational aspects of
dark energy research. The problem of the dark sector is introduced as
introducing

"two additional components in our Universe: a component behaves like cold
particles dubbed cold dark matter, and a component without significant
dynamics dubbed dark energy."

The authors later state,

"Data suggests that dark energy, an energy component probably coming from the
cosmological constant, dominates the current Universe. The percentage of dark
energy density is around 70% – not small nor too large. The Universe is now
accelerating due to the presence of dark energy."

But like I said earlier, the data suggests _acceleration_ for which dark
energy is one possible solution.

The authors then go on to enumerate some of the more popular theoretical
explanations for dark energy. A lot of this touches on field theory I'm rusty
on, and so little qualifies for something I fully understand. Note that there
are actually two theoretical problems associated with dark energy - (1) how to
cancel the gigantic value predicted from the ZPE of quantum fields and (2) how
to generate a teeny eny bit of dark energy:

A.) Some symmetry arguments from field theory, which the authors don't paint
as very convincing

B.) Anthropic principle (don't tell Matthew Buckley)

C.) Fine tuning - introducing a field that cancels the big boi value from
field theory

D.) Modified gravity - wouldn't that be awesome

E.) Quantum cosmology - could lambda and quantum gravity be connected somehow?
From a heuristic point of view this seems pretty compelling, but from a
theoretical perspective probably a rabbit hole atm

F.) Holographic principle - ??? We live in a black hole?

G.) Back-reaction - dark energy arising from some complications regarding the
fact that the Einstein field equations are non-linear. We assume the universe
is homog. and isot., but this isn't true on small scales. We first average
over small scales then time evolve. This introduces a correction term which
might explain DE - but uncertain if the effect could be large enough. Also -
what if the universe is not homogoneous on scales _larger_ than the observable
universe. Then we should have a similar effect!

H.) Phenomological models - ahh, sweet conservative methods. What if it's just
another boring field? An interesting consequence of such a model is that it's
quite easily constructed that w > -1 and w < -1. For the former, quintessence
always has w < -1 and for the latter phantom DE (quintessence with a flipped
sign on the kinetic term) has w < -1. The authors mention that in this case
one should also consider "perturbations" of the dark energy field as it has
"local degrees of freedom." Potentially a way to distinguish between this and
a cosmological constant.

The authors then move on to the more pedestrian concern of observational
probes of dark energy.

The first class of observational probes involves measuring the luminosity
distance or angular diameter distance. By measuring the luminosity distance,
you are measuring the integrated Hubble constant, since

d_L = \int_0^z dz'/H(z')

And the angular diameter distance is related by a factor of (1+z)^-2. So,
there are a few ways of doing this:

1.) SNIa - standard candles, give relatively direct measure of d_L. There are
several issues with systematic errors - SNIa identification, host galaxy dust
extinction, not _really_ standard candles, etc.

2.) CMB - can measure the "shift parameter" and the angular acoustic scale,
which give somewhat direct measurement of the angular diameter distance. Can
also measure the ISW effect, which probes the gravitational potential - has
been measured in cross-correlation with LSS at high signifigance.

3.) BAO - praise Eisenstein

4.) Weak lensing - something about the effect of DE on late-time structure
growth, has been used to constrain w.

5.) some other observational probes including galaxy clusters, GRBs, X-ray
observations, Hubble constant measurements, cosmic age test, and growth factor
data.

The authors then discuss different surveys, constraints on different
theoretical models, and model-independent methods in dark energy - which
doesn't seem super relevant to our work.

---

** 1401.0046 **

Provides a pedagological review of the standard foundation stuff.

They state the following "the title of this article follows the common but
inexact usage of “dark energy” as a catch-all term for the origin of cosmic
acceleration, regardless of whether it arises from a new form of energy or a
modification of GR."

They introduce a parametrization of w as either:

w = w_0 + w_a * (1-a)    [DETF parametrization]

w = w_p + w_a * (a_p - a)

The parameters of the second having been mentioned by the DETF. w_p and a_p
are the pivot scale factor and w, where the pivot redshift/scale factor is the
redshift at which you can best constrain w.

If we choose to go with Mpc instead of Mpc/h, we should (jokingly) advocate
that sigma_8 be renamed sigma_11.4286.

The authors state the following, which I liked:

"The underlying goal of empirical studies of cosmic acceleration is to address
two physically profound questions:
1. Does acceleration arise from a breakdown of GR on cosmological scales or
   from a new energy component that exerts repulsive gravity within GR?
2. If acceleration is caused by a new energy component, is its energy density
   constant in space and time, as expected for a fundamental vacuum energy, or
   does it show variations that indicate a dynamical field?"

The authors then list the different observational probes. Of particular note
here that wasn't emphasized in the previous article are redshift-space
distortions and the AP test.

Figure 1.1 is a good thing to look at for a potential way to present
differences between different cosmologies, although probably the obvious
avenue. I suggest we refrain from adding data to our figures since that would
date us rather quickly. I think this is a good way to show the differences
between different values of w though. It also makes some intuitive sense - w <
-1 causes more rapid expansion. Interesting bit in the figure caption "Note
that the SN data points can be shifted up or down by a constant factor to
account for freedom in the peak luminosity..."

Some Q's I have: 
1. Intuitively, why is stuff at the same redshift at different distances in
   different cosmologies? Naively, redshift measures the total "stretching" of
   space. I think this has to do with the fact that the relationship between
   proper distance and cosmological distance is related to the light-travel
   time between objects. So even though space has stretched by a constant
   amount, the distance can be different (want a more intuitive explanation
   though).
2. One can see in Fig 1.1 that the difference between wCDM and lambda-CDM
   saturates at z~1. Assuming the cosmological parameters are known (which is
   a big assumption in the precision case!), shouldn't one be able to
   constrain w with probes from arbitrarily large z? DETF claims that z >> 1
   probes aren't that useful. But there are so many more modes at z >> 1! (I
   think I've heard this question asked and explained many times so I'm a bit
   embarrased I haven't retained it.)
3. Is the (1+z)^n relationship between luminosity, angular, and comoving
   distances true even when w != -1? When w is not constant? When GR is
   modified? (last one might be a question for Justin Khoury)

In addition to looking w != -1, we should also include a discussion of
Omega_tot != 1, although the nature of the discussion is obviously different
from the original distance measures paper. But in a similar way to how we
might show slight differences between wCDM and lambdaCDM, we might also show
slight differences between curvedCDM (cCDM?) and lambdaCDM.

Figure 1.2 shows the current observational constraints on various cosmological
parameters. One thing we might think about including is the relationship
between the degeneracy of different parameters. For instance, suppose w = -1.1
but we enforce w = -1. How does this bias your measurement of Omega_m?
Omega_lambda? Similarly for curvature. This is probably well-documented
somewhere.

With both w and Omega_k, you can't really ever conclusively prove that w=-1 or
Omega_k=0, only to within some precision. Maybe we could add a table that has
two columns with the first column being some precision (e.g. w=-1 to 10^-3)
and the second column being some piece of interesting physics that is excluded
if that precision is ever measured. Similarly for if w > -1 or < -1 and
omega_k > 0 and < 0. This may be veering too hard into a dark energy review
though.

They then move into sigma_8 constraints. Structure formation, so not evidently
relevant to us.

---

** 1502.01590 **

Now we're in grown up territory, Planck 2015 XIV. Dark energy and
modified gravity.

They do a good job of saying we observe acceleration, it could be DE, but it
could also be modification to GR. One question I have - if its a modification
to GR, isn't this in tension with inflation since that would mean the universe
would be strongly curved today?

This paper uses the w = w_0 + w_a * (1-w_a) parametrization

Table 1 (and p. 2) nicely lays out and organizes all the alternatives to
lambdaCDM. They are organized into three sections, some sociological and some
physical:
1. Background parametrizations. The background cosmology is modified.
   Perturbations are included, but their evolution is driven solely by the
   background in a vanilla lambdaCDM. This includes wCDM, time evolution of w,
   PCA of w, early DE, and a weakly-couple canonical scalar field.
2. Perturbation expansions. The idea is that gravitational perturbations and
   their evolution are modified beyond what the background evolution would
   predict. I think this is just modified GR but I'm not sure? The two main
   classes considered are EFT and another "more phenomological" class
   considering arbitrary functions of the gravitational field.
3. Partcular models. These are models which are more theoretically mature and
   so easier to parametrize and thus constrain with data. Includes k-essense,
   f(R), EoS...

I think the spirit of distance measures would push us in the direction of
considering just 1.) background parametrizations, but we shouldn't give the
impression that 1.) is the most likely case just because it is the easiest to
understand or - god forbid - is the most aesthetically pleasing.

They also consider higher order expansions of w, but they don't fit the data
any better than lamdbaCDM or a linear expansion.

5.1.2 offers (finally) a new parametrization of w. If DE is a "minimally
coupled-scalar field" with a potential of form V = 0.5 m^2 phi^2, then we
expect w = -1 + \delta w(z) \approx -1 + \delta w_0 H_0^2/H(z)^2. \delta w_0
is then the only free parameter, but is not found to deviate from zero at any
significance.

---

** 1605.02702 **

Awesome paper. Writes down six of the bidimensional (two parameter) models of
DE.

1. Lambda CDM with w=-1 (only one free parameter, Omega_m). (I'm surprised
   wCDM is not included).
2. Linear-redshift approximation. The typical linear expansion of w, but the
   author uses z instead, so w = w_0 - w_1*z. Note that this is quite
   different from the regular parametrization, and the two can't be related
   simply since being linear in a and z are two different games.
3. The Chevallier-Polarski-Linder parametrization (CPL). w = w_0 +
   w_1*(z/(1+z)).
4. Barboza-Alcaniz approximation (BA). w = w_0 + w_1 * (z*(1+z))/(1+z^2). The
   author claims that this is desirable because it works even as z -> -1. Not
   sure how useful that really is.
5. Low correlation parametrization (LC). Little more unseemly - written below
   this. Has the virtue that w_0 and w_c are uncorrelated (by construction).
   Requires a special redshift z_c. Similar in taste to w_p parametrization,
   but focusing on correlation instead of constraining power.
6. Jassal-Bagla-Padmanabhan (JBP). w = w_0 + z/(1+z)^2 w_1. Alleviates some
   issues with CPL at high redshift.
7. Wetterich-redshift (WP) w = w_0 / (1 + w_1*ln(1+z))^2. This is an early
   DE-like model, with w_1 encoding the redshift of EDE (in some way). Some
   issues since this can't have w>0 at early times, which may be the case
   during radiation domination.

For 5:
w = ( (-z + z_c)*w_0 + z*(1 + z_c)*w_c) / ((1 + z) * z_c)

Author then does some data stuff.

---

** 1611.00036 **

DESI science paper.

They use the standard parametrization w = w_0 + w_a * (1-a). This really does
seem standard, and the pivot stuff is not in favor. The introduction of DE on
pp. 3-4 is good.

They also do a good job of separating acceleration of universe from dark
energy. However, they state "We have three possible explanations for the
accelerating expansion of the Universe: a cosmological constant, equivalent to
static dark energy with w = −1; a dynamical dark energy with w(a) != −1; or a
failure of General Relativity." However, I think that the cosmological
constant should be seen as a _special case_ of dark energy, as opposed to
equivalent to w=-1 DE.

I really like Fig. 2.1. Look! They even emphasize z > 1 measurements!! But
they also do a good job of showing the difference between different models
where w differs slightly from -1.

